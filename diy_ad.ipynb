{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY AD\n",
    "\n",
    "Minimalistic implementation of AD in python.\n",
    "The implementation is supposed to be minimal both in terms of lines-of-code and the concepts required for its implementation.\n",
    "Namely, we will use exactly one core concept: linearizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import jax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linearization can be though of as the implicit Jacobian matrix of a function (yes, the name \"linearization\" is misleading as it might imply having an offset that it does not have here).\n",
    "We need our implicit Jacobian matrix to have four attributes: a forward pass (Jacobian-Vector-Product), a backwards pass (Vector-Jacobian-Product), a reference to the parameters with respect to which we are going to differentiate to, and the value of the linearized function.\n",
    "The last attribute is required in order to amend the Jacobian.\n",
    "\n",
    "The forward pass of the Jacobian reapplies all linearized operators of our function in the order in which they were originally called.\n",
    "A simple recursion into the individual Jacobians of the operators is sufficient if each of them applies the chain rule correctly.\n",
    "The backwards pass is slightly trickier as we need to watch out for accumulating gradients.\n",
    "For this purpose of tracking accumulating gradients, our backwards pass will share a global `Tape` to which the gradient for each input to a function is accumulated on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identiy(*t, tape): return t\n",
    "\n",
    "\n",
    "class Linearization():\n",
    "    def __init__(self, p, fwd=identiy, bwd=identiy, _wrt=None):\n",
    "        self.p = p\n",
    "        self._fwd, self._bwd = fwd, bwd\n",
    "        # Reference initial parameters w.r.t. which we want to differentiate\n",
    "        self._wrt = self if _wrt is None else _wrt\n",
    "\n",
    "    def __call__(self, *t, tape=None):\n",
    "        if tape is not None:\n",
    "            return self._fwd(*t, tape=tape)\n",
    "        # Outermost call of Linearization (i.e. without a tape yet)\n",
    "        # `tape` serves as shared dict for gradient accumulation\n",
    "        tape = defaultdict(lambda: 0.)\n",
    "        o = self._fwd(*t, tape=tape)\n",
    "        assert len(o) == 1 if len(tape) == 0 else True\n",
    "        return o[0] if len(tape) == 0 else (tape[self._wrt], )\n",
    "\n",
    "    @property\n",
    "    def T(self):\n",
    "        return self.__class__(None, self._bwd, self._fwd, _wrt=self._wrt)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({self.p}, {self._fwd}, {self._bwd})\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining two simple functions (and their linearizations): `exp` and `add`.\n",
    "First, let's have a look at the unary function `exp`.\n",
    "Its Jacobian is a diagonal matrix as it is a point-wise operator.\n",
    "In terms of code, the forward and reverse of the linearization are thus simple multiplications.\n",
    "The diagonal operator, i.e. the multiplication, is amended once to the left of the Jacobian for the forward pass and once to the right for the backwards pass.\n",
    "\n",
    "Notice how in the implementation below the computation of the diagonal is hoisted out of the forward and reverse mode using a closure.\n",
    "This specific choice of rematerialization strategy can be easily configured by writing custom rules for functions.\n",
    "A custom rule is nothing more than a simple `isinstance` check for a `Linearization` in a function.\n",
    "\n",
    "The binary operator `add` is slightly more elaborate in that it takes two arguments and has to handle all permutations of linearizations versus no linearizations as input.\n",
    "The `isinstance` checks thus have four cases but conceptually works the same as `exp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(pl):\n",
    "    if isinstance(pl, Linearization):\n",
    "        y = exp(pl.p)\n",
    "        def fwd(*t, tape):\n",
    "            t = pl(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            return (y * t[0], )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1\n",
    "            t = pl.T(y * t[0], tape=tape)\n",
    "            assert len(t) == 1\n",
    "            tape[pl] += t[0]\n",
    "            return t\n",
    "        return Linearization(y, fwd, bwd, _wrt=pl._wrt)\n",
    "    return np.exp(pl)\n",
    "\n",
    "\n",
    "def add(pl_l, pl_r):\n",
    "    if isinstance(pl_l, Linearization) and not isinstance(pl_r, Linearization):\n",
    "        def bwd(*t, tape):\n",
    "            t = pl_l.T(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            tape[pl_l] += t[0]\n",
    "            return t\n",
    "        return Linearization(pl_l.p + pl_r, pl_l, bwd, _wrt=pl_l._wrt)\n",
    "    elif not isinstance(pl_l, Linearization) and isinstance(pl_r, Linearization):\n",
    "        def bwd(*t, tape):\n",
    "            t = pl_r.T(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            tape[pl_r] += t[0]\n",
    "            return t\n",
    "        return Linearization(pl_l + pl_r.p, pl_r, bwd, _wrt=pl_r._wrt)\n",
    "    elif isinstance(pl_l, Linearization) and isinstance(pl_r, Linearization):\n",
    "        def fwd(*t, tape):\n",
    "            tn = pl_l(*t, tape=tape)\n",
    "            assert len(tn) == 1\n",
    "            c = tn[0]\n",
    "            tn = pl_r(*t, tape=tape)\n",
    "            assert len(tn) == 1\n",
    "            c += tn[0]\n",
    "            return (c, )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1 and pl_l._wrt is pl_r._wrt\n",
    "            tape[pl_l] += t[0]\n",
    "            tape[pl_r] += t[0]\n",
    "            return (pl_l.T(*t, tape=tape), pl_r.T(*t, tape=tape))\n",
    "        return Linearization(pl_l.p + pl_r.p, fwd, bwd, _wrt=pl_l._wrt)\n",
    "    else:\n",
    "        return pl_l + pl_r\n",
    "\n",
    "\n",
    "def cost(p):\n",
    "    p = exp(p)\n",
    "    return add(exp(p), p)\n",
    "\n",
    "\n",
    "p0, t = 3.14, 2.\n",
    "p0lin = Linearization(np.array(p0))\n",
    "j = cost(p0lin)\n",
    "j(t), j.T(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.jvp(lambda p: jax.numpy.exp(jax.numpy.exp(p)) + jax.numpy.exp(p), (p0, ), (t, ))[1], jax.vjp(lambda p: jax.numpy.exp(jax.numpy.exp(p)) + jax.numpy.exp(p), p0)[1](t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = 1e-2 * np.arange(0, 9)\n",
    "ones = np.ones((9, ))\n",
    "y = exp(p0)\n",
    "j = exp(exp(Linearization(p0)))\n",
    "j(p0), j.T(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, jj_T = jax.vjp(lambda x: jax.numpy.exp(jax.numpy.exp(x)), p0.astype(float))\n",
    "_, jj_at_p0 = jax.jvp(lambda x: jax.numpy.exp(jax.numpy.exp(x)), (p0.astype(float), ), (p0, ))\n",
    "jj_at_p0, jj_T(ones)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How best to rematerialize in the Jacobian is a difficult question.\n",
    "The approach taken here is a flexible albeit lazy one: We let the user do it explicitly when defining the Jacobian.\n",
    "However, the design of building forward and backwards pass in general incentivizes sharing memory between both passes.\n",
    "Furthermore, it is trivial to hoist out constants via closures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_reduction(pl, n=32, n_cols=3):\n",
    "    if isinstance(pl, Linearization):\n",
    "        def fwd(*t, tape):\n",
    "            return (weighted_reduction(*pl(*t, tape=tape)), )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1\n",
    "            p_shp = pl.p.reshape(3, -1).shape\n",
    "            t_T, indices = np.zeros(p_shp), np.arange(n) % p_shp[0]\n",
    "            for i, idx in enumerate(indices):\n",
    "                super_expensive_weights = np.ones(p_shp[1:])\n",
    "                t_T[idx] += t[0][i] * super_expensive_weights\n",
    "            tape[pl] += t_T\n",
    "            return pl.T(t_T.reshape(pl.p.shape), tape=tape)\n",
    "        return Linearization(weighted_reduction(pl.p), fwd, bwd, _wrt=pl._wrt)\n",
    "    p = pl.reshape(n_cols, -1)\n",
    "    y, indices = np.zeros((n, )), np.arange(n) % p.shape[0]\n",
    "    for i, idx in enumerate(indices):\n",
    "        super_expensive_weights = np.ones(p.shape[1:])\n",
    "        y[i] = np.sum(p[idx] * super_expensive_weights)\n",
    "    return y\n",
    "\n",
    "\n",
    "p0lin = Linearization(np.arange(12, dtype=float))\n",
    "y2 = weighted_reduction(p0lin.p)\n",
    "j = weighted_reduction(p0lin)\n",
    "j(p0lin.p), j.T(y2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(p): return weighted_reduction(exp(p))\n",
    "\n",
    "p0 = 1e-2 * np.arange(0, 9)\n",
    "f0 = f(p0)\n",
    "f_ones = np.ones(f0.shape)\n",
    "\n",
    "j = f(Linearization(p0))\n",
    "j(p0), j.T(f_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum(pl):\n",
    "    if isinstance(pl, Linearization):\n",
    "        def fwd(*t, tape):\n",
    "            return (sum(*pl(*t, tape=tape)), )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1\n",
    "            tape[pl] = t = t[0] * np.ones(pl.p.shape)\n",
    "            return pl.T(t, tape=tape)\n",
    "        return Linearization(sum(pl.p), fwd, bwd, _wrt=pl._wrt)\n",
    "    return np.sum(pl)\n",
    "\n",
    "p0 = np.arange(0, 9, dtype=float)\n",
    "j = sum(Linearization(p0))\n",
    "j(p0), j.T(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow(pl, exponent):\n",
    "    if isinstance(pl, Linearization) and not isinstance(exponent, Linearization):\n",
    "        yl = exponent * pow(pl.p, exponent - 1)\n",
    "        def fwd(*t, tape):\n",
    "            t = pl(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            return (yl * t[0], )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1\n",
    "            tape[pl] = t = yl * t[0]\n",
    "            return pl.T(t, tape=tape)\n",
    "        return Linearization(pow(pl.p, exponent), fwd, bwd, _wrt=pl._wrt)\n",
    "    elif not isinstance(pl, Linearization) and not isinstance(exponent, Linearization):\n",
    "        return pl**exponent\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "y = pow(3., 3)\n",
    "j = pow(Linearization(3.), 3)\n",
    "j.T(4.), jax.vjp(lambda x: x**3, 3.)[1](4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 0.\n",
    "\n",
    "def h(p):\n",
    "    return add(sum(pow(add(-data, weighted_reduction(exp(p))), 2)), sum(pow(p, 2)))\n",
    "\n",
    "j = h(Linearization(p0))\n",
    "j(p0), j.T(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
