{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, namedtuple\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identiy(*t, tape): return t\n",
    "\n",
    "\n",
    "class Linearization():\n",
    "    def __init__(self, p, fwd=identiy, bwd=identiy, _wrt=None):\n",
    "        self.p = p\n",
    "        self._fwd, self._bwd = fwd, bwd\n",
    "        # Reference initial parameters w.r.t. which we want to differentiate\n",
    "        self._wrt = self if _wrt is None else _wrt\n",
    "\n",
    "    def __call__(self, *t, tape=None):\n",
    "        if tape is not None:\n",
    "            return self._fwd(*t, tape=tape)\n",
    "        # Outermost call of Linearization (i.e. without a tape yet)\n",
    "        # `tape` serves as shared dict for gradient accumulation\n",
    "        tape = defaultdict(lambda: 0.)\n",
    "        o = self._fwd(*t, tape=tape)\n",
    "        assert len(o) == 1 if len(tape) == 0 else True\n",
    "        return o[0] if len(tape) == 0 else (tape[self._wrt], )\n",
    "\n",
    "    @property\n",
    "    def T(self):\n",
    "        return self.__class__(None, self._bwd, self._fwd, _wrt=self._wrt)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({self.p}, {self._fwd}, {self._bwd})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(pl):\n",
    "    if isinstance(pl, Linearization):\n",
    "        y = exp(pl.p)\n",
    "        def fwd(*t, tape):\n",
    "            t = pl(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            return (y * t[0], )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1\n",
    "            t = pl.T(y * t[0], tape=tape)\n",
    "            assert len(t) == 1\n",
    "            tape[pl] += t[0]\n",
    "            return t\n",
    "        return Linearization(y, fwd, bwd, _wrt=pl._wrt)\n",
    "    return np.exp(pl)\n",
    "\n",
    "\n",
    "def add(pl_l, pl_r):\n",
    "    if isinstance(pl_l, Linearization) and not isinstance(pl_r, Linearization):\n",
    "        def bwd(*t, tape):\n",
    "            t = pl_l.T(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            tape[pl_l] += t[0]\n",
    "            return t\n",
    "        return Linearization(pl_l.p + pl_r, pl_l, bwd, _wrt=pl_l._wrt)\n",
    "    elif not isinstance(pl_l, Linearization) and isinstance(pl_r, Linearization):\n",
    "        def bwd(*t, tape):\n",
    "            t = pl_r.T(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            tape[pl_r] += t[0]\n",
    "            return t\n",
    "        return Linearization(pl_l + pl_r.p, pl_r, bwd, _wrt=pl_r._wrt)\n",
    "    elif isinstance(pl_l, Linearization) and isinstance(pl_r, Linearization):\n",
    "        def fwd(*t, tape):\n",
    "            t = pl_l(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            c = t[0]\n",
    "            t = pl_r(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            c += t[0]\n",
    "            return (c, )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1 and pl_l._wrt is pl_r._wrt\n",
    "            tape[pl_l] += t[0]\n",
    "            tape[pl_r] += t[0]\n",
    "            return (pl_l.T(*t, tape=tape), pl_r.T(*t, tape=tape))\n",
    "        return Linearization(pl_l.p + pl_r.p, fwd, bwd, _wrt=pl_l._wrt)\n",
    "    else:\n",
    "        return pl_l + pl_r\n",
    "\n",
    "\n",
    "def cost(p): return add(exp(p), p)\n",
    "\n",
    "x = 3.14\n",
    "p0lin = Linearization(np.array(x))\n",
    "j = cost(p0lin)\n",
    "j(2.), j.T(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.vjp(lambda p: jax.numpy.exp(p) + p, x)[1](2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = 1e-2 * np.arange(0, 9)\n",
    "ones = np.ones((9, ))\n",
    "y = exp(p0)\n",
    "j = exp(exp(Linearization(p0)))\n",
    "j(p0), j.T(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, jj_T = jax.vjp(lambda x: jax.numpy.exp(jax.numpy.exp(x)), p0.astype(float))\n",
    "_, jj_at_p0 = jax.jvp(lambda x: jax.numpy.exp(jax.numpy.exp(x)), (p0.astype(float), ), (p0, ))\n",
    "jj_at_p0, jj_T(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_reduction(pl, n=32, n_cols=3):\n",
    "    if isinstance(pl, Linearization):\n",
    "        def fwd(*t, tape):\n",
    "            return (weighted_reduction(*pl(*t, tape=tape)), )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1\n",
    "            p_shp = pl.p.reshape(3, -1).shape\n",
    "            t_T, indices = np.zeros(p_shp), np.arange(n) % p_shp[0]\n",
    "            for i, idx in enumerate(indices):\n",
    "                super_expensive_weights = np.ones(p_shp[1:])\n",
    "                t_T[idx] += t[0][i] * super_expensive_weights\n",
    "            tape[pl] += t_T\n",
    "            return pl.T(t_T.reshape(pl.p.shape), tape=tape)\n",
    "        return Linearization(weighted_reduction(pl.p), fwd, bwd, _wrt=pl._wrt)\n",
    "    p = pl.reshape(n_cols, -1)\n",
    "    y, indices = np.zeros((n, )), np.arange(n) % p.shape[0]\n",
    "    for i, idx in enumerate(indices):\n",
    "        super_expensive_weights = np.ones(p.shape[1:])\n",
    "        y[i] = np.sum(p[idx] * super_expensive_weights)\n",
    "    return y\n",
    "\n",
    "\n",
    "p0lin = Linearization(np.arange(12, dtype=float))\n",
    "y2 = weighted_reduction(p0lin.p)\n",
    "j = weighted_reduction(p0lin)\n",
    "j(p0lin.p), j.T(y2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(p): return weighted_reduction(exp(p))\n",
    "\n",
    "p0 = 1e-2 * np.arange(0, 9)\n",
    "f0 = f(p0)\n",
    "f_ones = np.ones(f0.shape)\n",
    "\n",
    "j = f(Linearization(p0))\n",
    "j(p0), j.T(f_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum(pl):\n",
    "    if isinstance(pl, Linearization):\n",
    "        def fwd(*t, tape):\n",
    "            return (sum(*pl(*t, tape=tape)), )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1\n",
    "            tape[pl] = t = t[0] * np.ones(pl.p.shape)\n",
    "            return pl.T(t, tape=tape)\n",
    "        return Linearization(sum(pl.p), fwd, bwd, _wrt=pl._wrt)\n",
    "    return np.sum(pl)\n",
    "\n",
    "p0 = np.arange(0, 9, dtype=float)\n",
    "j = sum(Linearization(p0))\n",
    "j(p0), j.T(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow(pl, exponent):\n",
    "    if isinstance(pl, Linearization) and not isinstance(exponent, Linearization):\n",
    "        yl = exponent * pow(pl.p, exponent - 1)\n",
    "        def fwd(*t, tape):\n",
    "            t = pl(*t, tape=tape)\n",
    "            assert len(t) == 1\n",
    "            return (yl * t[0], )\n",
    "        def bwd(*t, tape):\n",
    "            assert len(t) == 1\n",
    "            tape[pl] = t = yl * t[0]\n",
    "            return pl.T(t, tape=tape)\n",
    "        return Linearization(pow(pl.p, exponent), fwd, bwd, _wrt=pl._wrt)\n",
    "    elif not isinstance(pl, Linearization) and not isinstance(exponent, Linearization):\n",
    "        return pl**exponent\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "y = pow(3., 3)\n",
    "j = pow(Linearization(3.), 3)\n",
    "j.T(4.), jax.vjp(lambda x: x**3, 3.)[1](4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 0.\n",
    "\n",
    "def h(p):\n",
    "    return add(sum(add(-data, weighted_reduction(exp(p)))), sum(pow(p, 2)))\n",
    "\n",
    "j = h(Linearization(p0))\n",
    "j(p0)\n",
    "j.T(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jax.vjp(lambda x: (x + x).sum(), p0)[1](1.))\n",
    "print((lambda x: sum(add(x, x)))(Linearization(p0)).T(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
